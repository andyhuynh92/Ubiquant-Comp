{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9db683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from scipy.special import comb\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb974465",
   "metadata": {},
   "outputs": [],
   "source": [
    "## requires \n",
    "## import numpy as np \n",
    "## from scipy.special import comb\n",
    "## from itertools import combinations\n",
    "\n",
    "class CombinatorialPurgedGroupKFold():\n",
    "    def __init__(self, n_splits = 6, n_test_splits = 2, purge = 1, pctEmbargo = 0.01, **kwargs):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_test_splits = n_test_splits\n",
    "        self.purge = purge\n",
    "        self.pctEmbargo = pctEmbargo\n",
    "        \n",
    "    def split(self, X, y = None, groups = None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "            \n",
    "        u, ind = np.unique(groups, return_index = True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_groups = len(unique_groups)\n",
    "        group_dict = {}\n",
    "        for idx in range(len(X)):\n",
    "            if groups[idx] in group_dict:\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "                \n",
    "        n_folds = comb(self.n_splits, self.n_test_splits, exact = True)\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "            \n",
    "        mbrg = int(n_groups * self.pctEmbargo)\n",
    "        if mbrg < 0:\n",
    "            raise ValueError(\n",
    "                \"The number of 'embargoed' groups should not be negative\")\n",
    "        \n",
    "        split_dict = {}\n",
    "        group_test_size = n_groups // self.n_splits\n",
    "        for split in range(self.n_splits):\n",
    "            if split == self.n_splits - 1:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):].tolist()\n",
    "            else:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):int((split + 1) * group_test_size)].tolist()\n",
    "        \n",
    "        for test_splits in combinations(range(self.n_splits), self.n_test_splits):\n",
    "            test_groups = []\n",
    "            banned_groups = []\n",
    "            for split in test_splits:\n",
    "                test_groups += split_dict[split]\n",
    "                banned_groups += unique_groups[split_dict[split][0] - self.purge:split_dict[split][0]].tolist()\n",
    "                banned_groups += unique_groups[split_dict[split][-1] + 1:split_dict[split][-1] + self.purge + mbrg + 1].tolist()\n",
    "            train_groups = [i for i in unique_groups if (i not in banned_groups) and (i not in test_groups)]\n",
    "\n",
    "            train_idx = []\n",
    "            test_idx = []\n",
    "            for train_group in train_groups:\n",
    "                train_idx += group_dict[train_group]\n",
    "            for test_group in test_groups:\n",
    "                test_idx += group_dict[test_group]\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f6e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('parquet/train_low_mem.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781ae4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_col = ['time_id']\n",
    "f_col = []\n",
    "for i in range(0,300):\n",
    "    time_col.append('f_'+str(i))\n",
    "    f_col.append('f_'+str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a0304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#polars implementation\n",
    "#df.select(pl.col('*').cast(pl.Float16))\n",
    "\n",
    "df = df.astype('float16')\n",
    "df['time_id'] = df['time_id'].astype('int32')\n",
    "df_x = df[time_col]\n",
    "df_y = pd.DataFrame(df['target'])\n",
    "\n",
    "## Consider deleting df for memory\n",
    "## del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58521122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Done\n",
      "CPU times: user 1h 39min 35s, sys: 5min 51s, total: 1h 45min 27s\n",
      "Wall time: 17min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv = CombinatorialPurgedGroupKFold().split(df_x, df_y, groups = df_x['time_id'])\n",
    "\n",
    "models = []\n",
    "i = 0\n",
    "for tr, val in cv:\n",
    "    print(i)\n",
    "    X_train = df_x.loc[tr][f_col]#.to_parquet(f'xtrain{i}.parquet')\n",
    "    y_train = df_y.loc[tr]#.to_parquet(f'ytrain{i}.parquet')\n",
    "    \n",
    "    model = lgb.LGBMRegressor()\n",
    "    model.fit(X_train, y_train, eval_metric='rmse')\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d2b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict(df_x[f_col])\n",
    "    preds.append(pred)\n",
    "finalpred = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "237ef2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00869107, -0.04353364,  0.04574885, ...,  0.02985028,\n",
       "        0.01785094,  0.01530847])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalpred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3be01f",
   "metadata": {},
   "source": [
    "Pickling the models for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c84358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for i in range(len(models)):\n",
    "    string = 'lgbmmodel'+str(i)+'.pkl'\n",
    "    filepath = open(string, 'wb')\n",
    "    pickle.dump(models[i], filepath)\n",
    "    filepath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06e4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
